{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "source": [
    "# Traffic Sign Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Disable GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as sk_metrics\n",
    "\n",
    "# Traffic sign specific code\n",
    "import tsdata\n",
    "import mlutil\n",
    "import mlvis\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"GPUs availability: \", tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MqDQO0KCaWS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"part_1a\"\n",
    "\n",
    "num_classes = 21\n",
    "\n",
    "if task == \"part_1a\":\n",
    "    # High performance model\n",
    "\n",
    "    dpconfig = tsdata.DataPipelineConfig(\n",
    "        target_width  = 32,\n",
    "        target_height = 32,\n",
    "        is_color_mode = True,\n",
    "        augmentation  = \"fliplr\"\n",
    "    )\n",
    "\n",
    "    class_weight = None\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape = dpconfig.get_keras_input_shape()),\n",
    "      tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(64,  activation = 'relu'),\n",
    "      tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    # Larger image classification models - overkill for this problem!\n",
    "\n",
    "    # base_model = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = dpconfig.get_keras_input_shape()) \n",
    "    # x=base_model.output\n",
    "    # x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    # x=tf.keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
    "    # model=tf.keras.Model(base_model.input,x)\n",
    "\n",
    "    # base_model = tf.keras.applications.NASNetMobile(weights = None, include_top = False, input_shape = dpconfig.get_keras_input_shape()) \n",
    "    # x=base_model.output\n",
    "    # x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    # x=tf.keras.layers.Dense(num_classes, activation = 'softmax')(x)\n",
    "    # model=tf.keras.Model(base_model.input,x)\n",
    "\n",
    "    # model = tf.keras.applications.NASNetMobile(weights = None, include_top = True, input_shape = dpconfig.get_keras_input_shape(), classes = num_classes) \n",
    "\n",
    "elif task == \"part_1b\":\n",
    "    # Smaller model\n",
    "\n",
    "    dpconfig = tsdata.DataPipelineConfig(\n",
    "        target_width  = 16,\n",
    "        target_height = 16,\n",
    "        is_color_mode = False,\n",
    "        augmentation  = \"fliplr\"\n",
    "    ) \n",
    "    \n",
    "    class_weight = None\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape = dpconfig.get_keras_input_shape()),\n",
    "      tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "elif task == \"part_2\":\n",
    "    # Extra emphasis on left and right turn signs\n",
    "\n",
    "    # Using two attempts to improve classification of these two signs:\n",
    "    #   a) Getting more data, by making use of the fact that these two classes are horizontally mirrored.\n",
    "    #      The actual augmentation happens in function \"load_data_fresh\" in \"load.py\".\n",
    "    #   b) Increase the class weights for these two classes\n",
    "        \n",
    "    dpconfig = tsdata.DataPipelineConfig(\n",
    "        target_width  = 32,\n",
    "        target_height = 32,\n",
    "        is_color_mode = True,\n",
    "        augmentation  = \"turnimprove\"  # Make use of symmetries of the 2 classes we want to improve\n",
    "    )    \n",
    "        \n",
    "    # Put stronger emphasis on the classes of interest\n",
    "    class_weight = dict()\n",
    "    for class_idx in range(num_classes):\n",
    "      class_weight[class_idx] = 1.0\n",
    "    class_weight[12] = 2.0\n",
    "    class_weight[13] = 2.0\n",
    "        \n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape = dpconfig.get_keras_input_shape()),\n",
    "      tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(64,  activation = 'relu'),\n",
    "      tf.keras.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "else:\n",
    "    raise RuntimeError(\"Invalid task!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = tsdata.load_data(dpconfig, \"train\")\n",
    "test_images,  test_labels  = tsdata.load_data(dpconfig, \"test\")\n",
    "\n",
    "class_names = tsdata.get_class_names()\n",
    "\n",
    "num_classes_actual = len(class_names)\n",
    "\n",
    "if num_classes_actual != num_classes:\n",
    "    raise RuntimeError(\"Unexpected number of classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "print(f\"train_images.shape = {train_images.shape}\")\n",
    "print(f\"len(train_labels)  = {len(train_labels)}\")\n",
    "print(f\"test_images.shape  = {test_images.shape}\")\n",
    "print(f\"len(test_labels)   = {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "### Visually inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap = None if dpconfig.is_color_mode else 'gray')\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_family_name = mlutil.generate_model_family_name(dpconfig, friendly_name = task)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback_history     = tf.keras.callbacks.History()\n",
    "callback_earlystop   = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 20, mode = \"min\")\n",
    "callback_checkpoint  = mlutil.get_model_checkpointer(model_family_name)\n",
    "\n",
    "model.fit(train_images, train_labels, validation_split = 0.2, epochs = 200, class_weight = class_weight,\n",
    "  callbacks = [callback_history, callback_earlystop, callback_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Choose optimum model based on validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = np.asarray(callback_history.history[\"val_loss\"])\n",
    "optimum_epoch_num = np.argmin(val_losses) + 1\n",
    "\n",
    "print(f\"Optimum model: epoch = {optimum_epoch_num}, val_loss = {val_losses[optimum_epoch_num - 1]:.3f}\")\n",
    "\n",
    "print(f\"Loading optimum model weights (epoch {optimum_epoch_num})...\")\n",
    "mlutil.load_model_epoch(model, model_family_name, optimum_epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show model summary / computational effort\n",
    "For these simple models, the number of parameters correlates with the computational effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute model accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print(f\"\\nAccuracy on test set: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)\n",
    "labels_predicted = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate class-wise report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sk_metrics.classification_report(test_labels, labels_predicted, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confmat = tf.math.confusion_matrix(test_labels, labels_predicted, num_classes)\n",
    "mlvis.plot_traffic_sign_confmat(confmat, normalize_by = \"cols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "### Verify predictions\n",
    "\n",
    "Manual inspection of some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,2,1)\n",
    "mlvis.plot_image(class_names, predictions[i], test_labels[i], test_images[i])\n",
    "plt.subplot(1,2,2)\n",
    "mlvis.plot_value_array(class_names, predictions[i],  test_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,2,1)\n",
    "mlvis.plot_image(class_names, predictions[i], test_labels[i], test_images[i])\n",
    "plt.subplot(1,2,2)\n",
    "mlvis.plot_value_array(class_names, predictions[i],  test_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Overview of more predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  mlvis.plot_image(class_names, predictions[i], test_labels[i], test_images[i])\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  mlvis.plot_value_array(class_names, predictions[i], test_labels[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Improvement Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a **larger dataset**, e.g., the full dataset available at: http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset\n",
    "* Apply more advanced **image enhancement**: gamma correction, histogram stretching, ...\n",
    "* Do more **augmentation**: perspective transformation, rotation, ...\n",
    "* Explore more **model architectures**, i.e., try out more advanced models that perform well in image classification tasks\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
